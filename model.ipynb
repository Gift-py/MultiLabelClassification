{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'm going to basically try to predict the missing values in the \"Market Category\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean, std\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Engine Fuel Type'].fillna(method='ffill', inplace=True)\n",
    "df['Engine HP'].fillna(df['Engine HP'].median(), inplace = True)\n",
    "df['Engine Cylinders'].fillna(df['Engine Cylinders'].mean(), inplace = True)\n",
    "df['Number of Doors'].fillna(method='ffill', inplace = True)\n",
    "df.drop('Model', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to drop the model of the car\n",
    "#to OHE categorical columns\n",
    "\n",
    "# categorical_columns = ['Make', 'Engine Fuel Type', 'Transmission Type', 'Driven_Wheels', 'Vehicle Size', 'Vehicle Style']\n",
    "\n",
    "# #encoding of categorical columns\n",
    "# for column in categorical_columns:\n",
    "#     tempdf = pd.get_dummies(df[column],  prefix=column)\n",
    "#     df = pd.concat([df, tempdf], axis=1)\n",
    "\n",
    "#     df.drop(column, axis=1, inplace=True)\n",
    "\n",
    "#WE DO NOT REALLY NEED TO ENCODE SINCE WEKA WOULD TAKE CARE OF THIS ISSUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Market Category\n",
    "#this is a categorical column\n",
    "lst = df['Market Category'].unique()\n",
    "\n",
    "category_list = []\n",
    "#loop extracts unique label for the market category column \n",
    "for i in lst:\n",
    "    if isinstance(i, str):\n",
    "        if ',' in i:\n",
    "            new_list = i.split(',')\n",
    "            for j in new_list:\n",
    "                if j in category_list:\n",
    "                    print(j, 'already found')\n",
    "                    continue\n",
    "                else:\n",
    "                    category_list.append(j)\n",
    "                    print(j, 'added')\n",
    "        else:\n",
    "            if i in category_list:\n",
    "                print(i, 'already found')\n",
    "                continue\n",
    "            else:\n",
    "                category_list.append(i)\n",
    "                print(i, 'added')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df containg rows with missing market category (test_df)\n",
    "prediction_df = df.loc[df['Market Category'].isna()]\n",
    "#drop rows with missing market category\n",
    "df.drop(df.index[df['Market Category'].isna()], inplace=True)\n",
    "#drop market category column\n",
    "prediction_df.drop('Market Category', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output column ('y')\n",
    "df_y = df.pop('Market Category')\n",
    "#changing format of column rows into one that is easier to encode\n",
    "df_y = df_y.apply(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "#df_y = df_y.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom OHE function for y_column\n",
    "\n",
    "def ohe_list(df_col, categories):\n",
    "    #create a dictionary map\n",
    "    label_to_int = dict((c, i) for i, c in enumerate(categories))\n",
    "    #int_to_label = dict((i, c) for i, c in enumerate(categories))\n",
    "\n",
    "    #encode to integer\n",
    "    label_encoded = [[[label_to_int[label] for label in cell.split(',') ] for cell in row] for row in df_col]\n",
    "\n",
    "    #create one hot list\n",
    "    oh_list = list()\n",
    "\n",
    "    for row in label_encoded:\n",
    "        for cell in row:\n",
    "            cell_enc = [0 for _ in range(len(categories))]\n",
    "            for label in cell:\n",
    "                cell_enc[label] = 1\n",
    "            oh_list.append(cell_enc)\n",
    "\n",
    "    return oh_list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_enc = ohe_list(df_y, category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_enc = pd.DataFrame(df_y_enc)\n",
    "df_y_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_inputs, n_outputs):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "\tmodel.add(Dense(n_outputs, activation='sigmoid'))\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\treturn model\n",
    "\n",
    "#really lame model lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X, y):\n",
    "    results = list()\n",
    "    n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "\n",
    "    #defining evaluation precedure\n",
    "    cross_val = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    for train, test in cross_val.split(X):\n",
    "        X_train, X_test = X.loc[train, X.columns], X.loc[test, X.columns]\n",
    "        y_train, y_test = y.loc[train, y.columns], y.loc[test, y.columns]\n",
    "\n",
    "        model = get_model(n_inputs, n_outputs)\n",
    "        model_history = model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "        y_hat = model.predict(X_test)\n",
    "        y_hat = y_hat.round()\n",
    "\n",
    "        acc = accuracy_score(y_test, y_hat)\n",
    "        print('\\n >%.3f \\n\\n' %acc)\n",
    "        results.append(acc)\n",
    "    return results, model_history\n",
    "        \n",
    "#well this was pointless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results, model_hist = evaluate_model(df, df_y_enc)\n",
    "#print('Accuracy: %.3f (%.3f)' % (mean(results), std(results)))\n",
    "\n",
    "#avg accuracy is 30% (really poor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new data set to use on weka "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_axis'] = df_y_enc[df_y_enc.columns[0:]].apply(lambda x: [i for i in x], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('to_predict.csv')  #this csv file was deleted\n",
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.drop(test_df['index'], axis=1, inplace=True)\n",
    "del test_df['index']\n",
    "test_df.reset_index(inplace=True)\n",
    "test_df['y_axis'] = '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('to_pred.csv', index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES ###\n",
    "-> Weka can only predice a certain amount of supplied test values at a time (Well at least I have'nt found a way around it)  \n",
    "\n",
    "-> The test dataset (to_predict) must have the same columns as the train dataset when suppling to weka (including the column with missing values... all you have to do is to populate that column with \"?\")  \n",
    "\n",
    "-> Javabridge installation is not working (I have to find a way to fix this asap!)  \n",
    "\n",
    "-> Decode function not yet imlpemented (This would be completed later)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fb6802bca10536631454388dc7754e14df50e11a5efcab5b6d4dac13af1b70b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
